{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-e61b8f99-434b-4848-a553-4bbae63045cc",
    "deepnote_cell_height": 156.390625,
    "deepnote_cell_type": "markdown",
    "id": "XUZ1dFPHzAHl"
   },
   "source": [
    "<h1><center>Laboratorio 9: Benchmark Estadístico con Reddit 🧮</center></h1>\n",
    "\n",
    "<center><strong>MDS7202: Laboratorio de Programación Científica para Ciencia de Datos</strong></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-231091e0-d755-42af-83b0-809301b54cfe",
    "deepnote_cell_height": 165.1875,
    "deepnote_cell_type": "markdown",
    "id": "UD8X1uhGzAHq"
   },
   "source": [
    "### Cuerpo Docente:\n",
    "\n",
    "- Profesor: Pablo Badilla\n",
    "- Auxiliar: Ignacio Meza D.\n",
    "- Ayudante: Patricio Ortiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00002-65747a66-3e34-4df6-9e4a-c63f6d47f1f1",
    "deepnote_cell_height": 171.796875,
    "deepnote_cell_type": "markdown",
    "id": "tXflExjqzAHr"
   },
   "source": [
    "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no serán revisados\n",
    "\n",
    "- Nombre de alumno 1: Sebastián Tinoco\n",
    "- Nombre de alumno 2:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-f842b0e0-851a-405c-a104-53fa53260fa5",
    "deepnote_cell_height": 62,
    "deepnote_cell_type": "markdown",
    "id": "AD-V0bbZzAHr"
   },
   "source": [
    "### **Link de repositorio de GitHub:** https://github.com/sebatinoco/MDS7202/tree/main/lab9`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00004-d2b77039-39dd-4985-bec7-914bd5a67d98",
    "deepnote_cell_height": 669,
    "deepnote_cell_type": "markdown",
    "id": "6uBLPj1PzAHs"
   },
   "source": [
    "# Temas a tratar\n",
    "\n",
    "- Optimización de Código en Python.\n",
    "- Utilización de librerías para medir el tiempo de ejecución de funciones.\n",
    "- Métodos para optimizar el rendimiento de las funciones.\n",
    "\n",
    "# Reglas:\n",
    "\n",
    "- Fecha de entrega: 3/12/2021\n",
    "- **Grupos de 2 personas**\n",
    "- **Ausentes** deberán realizar la actividad solos. \n",
    "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente serán respondidos por este medio.\n",
    "- Prohibidas las copias. \n",
    "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
    "\n",
    "# Objetivos principales del laboratorio\n",
    "\n",
    "- Utilizar la API de Reddit a partir de la librería `praw` y visualizar cuales post son más probables que sean puntuados positivamente.\n",
    "- Utilizar `cache_lru` para cachear resultados de funciones.\n",
    "- Aplicar un atajo estadístico para obtener la mean posterior de datos.\n",
    "- Medir el tiempo de ejecución como también el uso de memoria de la función anterior.\n",
    "- Optimizar la función anterior a través de `numba`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-5a5cbaa6-e809-4c62-9709-7e650430b7ba",
    "deepnote_cell_height": 52.390625,
    "deepnote_cell_type": "markdown",
    "id": "MhISwri4zAHy"
   },
   "source": [
    "#Importamos librerias utiles 😸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00006-375e81a0-63bd-4f61-a2c2-561059d97241",
    "deepnote_cell_height": 168,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 214,
    "execution_start": 1638299125300,
    "id": "QGF3HgG2OF9W",
    "source_hash": "251d15fd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00006-00a9ab85-c6e5-4b3d-b6ba-2004ff409a6d",
    "deepnote_cell_height": 432.1875,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 24248,
    "execution_start": 1638299092849,
    "id": "cO7AQ9ciQ59U",
    "source_hash": "1240e4a3"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install praw\n",
    "!pip install line_profiler\n",
    "%load_ext line_profiler\n",
    "!pip install memory_profiler # instalamos memory profiler\n",
    "%load_ext memory_profiler\n",
    "!pip install numba\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import praw\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import jit\n",
    "import plotly.express as px\n",
    "from functools import lru_cache\n",
    "from IPython.core.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00007-853a08fe-06d7-4051-b347-1e29226924ee",
    "deepnote_cell_height": 82,
    "deepnote_cell_type": "markdown",
    "id": "xpOTbQcxbSiy"
   },
   "source": [
    "# 1. Recomendando Posts de Subreddit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00008-ca941d35-4377-406f-8b9c-cdf3ce096c64",
    "deepnote_cell_height": 376,
    "deepnote_cell_type": "markdown",
    "id": "3Q93vbNS25bM",
    "owner_user_id": "d50c3174-babb-4861-9c71-7e3af66458b8"
   },
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://preview.redd.it/3sxusxcjge791.png?auto=webp&s=88bc1f9a3c59eafda24b0e32dd87d7cf596d205d\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00009-bb6e6ae1-d939-400e-aa39-a9b5cf6fe725",
    "deepnote_cell_height": 245.59375,
    "deepnote_cell_type": "markdown",
    "id": "jnmZfFpxTTYX"
   },
   "source": [
    "Unos intrépidos alumnos del curso, quienes frecuentemente participan en subreddits y foros de reviews, se preguntan lo siguiente: ¿Podremos confiar que un post es bueno, si este tiene solamente 1 o 3 votos positivos?. los compañeros, creen que esto claramente no representa una opinión general, ya que estamos mucho menos seguros acerca de la verdadera proporción de votos a favor de los comentarios con pocos datos. ¿Pero cómo podemos obtener una representación más creíble para este problema?.\n",
    "\n",
    "Lo señalado forma parte de un problema estadísticos, donde a través del cálculo de la posterior se puede conocer que tan probable es que un post sea bueno. Para efectos de este laboratorio, no se exige un conocimiento previo para resolver este problema, simplemente se deberá aplicar las ecuaciones presentadas más adelante (De igual forma si quedan interesados sobre el tema se les invita a tomar el ramo [CC6104](https://github.com/dccuchile/CC6104))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00010-11ff1022-47d3-4e16-a067-862aff4fa1e6",
    "deepnote_cell_height": 70,
    "deepnote_cell_type": "markdown",
    "id": "xdbrb3AMi6EF"
   },
   "source": [
    "## 1.1 Obtención de Subrredits y Análisis [1 Punto]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00011-098a5246-642a-47aa-9f10-2261697c2603",
    "deepnote_cell_height": 363.796875,
    "deepnote_cell_type": "markdown",
    "id": "YI-IRspcjPee"
   },
   "source": [
    "Para estudiar que tan probable es que un post sea positivo se comenzará cargando datos reales del subreddit chile desde reddit (si usted desea puede cambiar el subreddit a uno de su gusto). Para esto le proponemos la utilización de la función que aparece mas abajo, la que presenta un usuario ya creado por el equipo docente. Dese un tiempo para entender que hace cada parte de la función, visualizando que se obtiene de estas.\n",
    "\n",
    "Revisada la función, utilice un **perfilador** para monitorear el tiempo y memoria que les toma a cada liena de código para ser ejecutada. Señale cuales son los procesos que mas tiempo consumen en la ejecución del Código, comentando si es posible mejorar el desempeño de la función.\n",
    "\n",
    "**TO-DO:**\n",
    "- [ ] Estudiar la función propuesta por el equipo docente.\n",
    "- [ ] Estudiar los tiempos de ejecución del código a través de un perfilador.\n",
    "- [ ] Estudiar la memoria ocupada por el código a través de un perfilador.\n",
    "- [ ] Comente los resultados. ¿Qué lineas ocupan más memoria o más/menos tiempo?¿Por qué?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00012-48fd53e5-c751-4583-b193-5f95afab5819",
    "deepnote_cell_height": 675,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1637947497504,
    "id": "R4PQbceVPJzh",
    "source_hash": "a55fad36"
   },
   "outputs": [],
   "source": [
    "def praw_reddit(nombre_subreddit=\"chile\", n_hot=1000):\n",
    "    reddit = praw.Reddit(\n",
    "        client_id=\"-w2hyFINxZ8T3g\",\n",
    "        client_secret=\"zGPCI4s3g6Ic6AsRi7vIpP0NoxbFdw\",\n",
    "        password=\"ClasesMDS7202\",\n",
    "        user_agent=\"Clases\",\n",
    "        username=\"DocenciaDataScience\",\n",
    "        check_for_async=False,\n",
    "    )\n",
    "    subreddit = reddit.subreddit(nombre_subreddit)\n",
    "\n",
    "    votes, post, url = {}, {}, {}\n",
    "    top_submissions = list(subreddit.hot(limit=n_hot)) # obtenemos el top n de posts del foro\n",
    "    for it, top_n in enumerate(range(50, len(top_submissions), 50)):\n",
    "        top_n_submissions = top_submissions[:top_n] # obtiene los primeros 50 posts\n",
    "        upvotes, downvotes, url[it], post[it] = [], [], [], []\n",
    "\n",
    "        for submission in top_n_submissions: # para cada uno de los posts\n",
    "            try:\n",
    "                ratio = submission.upvote_ratio # obtenemos el ratio de upvote\n",
    "                ups = int( # calculamos upvotes\n",
    "                    round((ratio * submission.score) / (2 * ratio - 1))\n",
    "                    if ratio != 0.5\n",
    "                    else round(submission.score / 2)\n",
    "                )\n",
    "                upvotes.append(ups) # guardamos upvotes\n",
    "                downvotes.append(ups - submission.score) # guardamos downvotes\n",
    "                post[it].append(submission.title) # guardamos titulo del post\n",
    "                url[it].append(submission.url) # guardamos url\n",
    "            except Exception as e: # en caso de error, sigue \n",
    "                continue\n",
    "        votes[it] = np.array([upvotes, downvotes]).T\n",
    "    return votes, post, url # retorna votos, post y url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00013-c9f108eb-9054-438f-9360-21669aced1bb",
    "deepnote_cell_height": 81,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 11242,
    "execution_start": 1637947497523,
    "id": "v4rjrWf_pJHJ",
    "source_hash": "4b31fefe"
   },
   "outputs": [],
   "source": [
    "votes, post, url = praw_reddit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TE6dfUMFTK7G"
   },
   "source": [
    "El propósito del código adjunto es obtener métricas (*upvotes*, *downvotes*, *título* y *url*) de posts en el subreddit de \"chile\". En general, la implementación sigue los siguientes pasos:\n",
    "\n",
    "1. Instanciar la clase `reddit` en el subreddit `nombre_subreddit`\n",
    "2. Obtener los primeros `n_hot` posts del subreddit especificado\n",
    "3. En batchs de 50, obtener *upvotes*, *downvotes*, *título* y *url* de cada uno de los posts y luego los guarda en una listas dentro de un diccionario (en el caso de *upvotes* y *downvotes*, estos son guardados en np.arrays dentro del diccionario).\n",
    "4. Finalmente, la función devuelve los diccionarios generados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "00014-ab26b98a-d355-4ce3-909a-c76ea78ab2b3",
    "deepnote_cell_height": 84,
    "deepnote_cell_type": "code",
    "id": "pDafgk9xOF9d"
   },
   "outputs": [],
   "source": [
    "# estudio de tiempos de ejecución\n",
    "%lprun -f praw_reddit praw_reddit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6za4dOjiWWCC",
    "outputId": "c2431b76-55a4-414d-d8cd-e9261d03ab34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 258.73 MiB, increment: 0.95 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit praw_reddit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QXkbl98GOF9e",
    "outputId": "fe0c811c-0fd5-48fc-ec53-6d6cf3ede48d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting praw_module.py\n"
     ]
    }
   ],
   "source": [
    "%%file praw_module.py\n",
    "import numpy as np\n",
    "import praw\n",
    "def praw_reddit(nombre_subreddit=\"chile\", n_hot=1000):\n",
    "    reddit = praw.Reddit(\n",
    "        client_id=\"-w2hyFINxZ8T3g\",\n",
    "        client_secret=\"zGPCI4s3g6Ic6AsRi7vIpP0NoxbFdw\",\n",
    "        password=\"ClasesMDS7202\",\n",
    "        user_agent=\"Clases\",\n",
    "        username=\"DocenciaDataScience\",\n",
    "        check_for_async=False,\n",
    "    )\n",
    "    subreddit = reddit.subreddit(nombre_subreddit)\n",
    "\n",
    "    votes, post, url = {}, {}, {}\n",
    "    top_submissions = list(subreddit.hot(limit=n_hot)) # obtenemos el top n de posts del foro\n",
    "    for it, top_n in enumerate(range(50, len(top_submissions), 50)):\n",
    "        top_n_submissions = top_submissions[:top_n] # obtiene los primeros 50 posts\n",
    "        upvotes, downvotes, url[it], post[it] = [], [], [], []\n",
    "\n",
    "        for submission in top_n_submissions: # para cada uno de los posts\n",
    "            try:\n",
    "                ratio = submission.upvote_ratio # obtenemos el ratio de upvote\n",
    "                ups = int( # calculamos upvotes\n",
    "                    round((ratio * submission.score) / (2 * ratio - 1))\n",
    "                    if ratio != 0.5\n",
    "                    else round(submission.score / 2)\n",
    "                )\n",
    "                upvotes.append(ups) # guardamos upvotes\n",
    "                downvotes.append(ups - submission.score) # guardamos downvotes\n",
    "                post[it].append(submission.title) # guardamos titulo del post\n",
    "                url[it].append(submission.url) # guardamos url\n",
    "            except Exception as e: # en caso de error, sigue \n",
    "                continue\n",
    "        votes[it] = np.array([upvotes, downvotes]).T\n",
    "    return votes, post, url # retorna votos, post y url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JNVRO7WrWALq",
    "outputId": "18a6df0c-796a-4005-95a9-3a449b871074"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "PYDEV DEBUGGER WARNING:\n",
      "sys.settrace() should not be used when the debugger is being used.\n",
      "This may cause the debugger to stop working correctly.\n",
      "If this is needed, please check: \n",
      "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
      "to see how to restore the debug tracing back correctly.\n",
      "Call Location:\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/memory_profiler.py\", line 845, in enable\n",
      "    sys.settrace(self.trace_memory_usage)\n",
      "\n",
      "\n",
      "PYDEV DEBUGGER WARNING:\n",
      "sys.settrace() should not be used when the debugger is being used.\n",
      "This may cause the debugger to stop working correctly.\n",
      "If this is needed, please check: \n",
      "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
      "to see how to restore the debug tracing back correctly.\n",
      "Call Location:\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/memory_profiler.py\", line 848, in disable\n",
      "    sys.settrace(self._original_trace_function)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from praw_module import praw_reddit \n",
    "\n",
    "%mprun -f praw_reddit praw_reddit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00015-ba1d4036-9f0c-49c7-885f-be416a89deb8",
    "deepnote_cell_height": 52.390625,
    "deepnote_cell_type": "markdown",
    "id": "-diI_GpXmzqS"
   },
   "source": [
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00016-64888967-a91d-455b-9d60-d105f449ae74",
    "deepnote_cell_height": 52.390625,
    "deepnote_cell_type": "markdown",
    "id": "6gdqQBi1m_cu"
   },
   "source": [
    "Notamos que los tiempos de ejecución de la función están totalmente cargados hacia la línea `top_submissions = list(subreddit.hot(limit=n_hot))`, tomando el 99.4% del tiempo total de ejecución. El resto del tiempo se lo toma en su mayoría los *append* que se hacen para guardar los valores en las listas. Así, es esperable que la mayor cantidad del tiempo sea destinado a obtener los posts del foro, pues implica obtener hacer una \"query\" a la API de reddit, esperar que sea procesada y luego obtener la respuesta, generando automáticamente un tiempo de espera mayor.\n",
    "\n",
    "Finalmente, notamos que casi la totalidad de la memoria de la función está siendo usada en la línea `def praw_reddit(nombre_subreddit=\"chile\", n_hot=1000)`, es decir, en la definción de la función `praw_reddit`. De esta forma, como definir una función global implica que tenga que ser guardada en el *runtime* de Python y pueda ser llamada en cualquier momento, es natural que sea la línea con uso de memoria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00017-2673822e-79de-4fbe-86af-5fd583216f57",
    "deepnote_cell_height": 70,
    "deepnote_cell_type": "markdown",
    "id": "tNDS2OpFnMnH"
   },
   "source": [
    "## 1.2 LRU y Análisis de Tiempo con Cache [1 Punto]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00018-d9701b8d-f3fe-4cd1-9f59-295dfdaeca48",
    "deepnote_cell_height": 380.796875,
    "deepnote_cell_type": "markdown",
    "id": "i3nsxCbAna4t"
   },
   "source": [
    "Respondan las siguientes preguntas:\n",
    "\n",
    "1.\t¿Qué es la memoria cache y a que se refiere las siglas LRU?\n",
    "2.\t¿Cuáles son los costos que tiene la aplicación de técnicas de Caching?\n",
    "3. ¿Cuál es la consecuencía de ocupar caching en la función anterior?.\n",
    "\n",
    "Respondidas las preguntas, se le solicita que aplique alguna técnica de caching para mejorar el desempeño de la función `praw_reddit`. Para esto compare solo el tiempo de ejecución del algoritmo con y sin caching, señalando el tiempo total de ejecución y el tiempo promedio que le toma ejecutar cada loop a la función. Con lo anterior, ¿es posible visualizar mejoras en este caso?.\n",
    "\n",
    "\n",
    "**TO-DO:**\n",
    "- [ ] Responder las preguntas.\n",
    "- [ ] Mejorar el código con cache.\n",
    "- [ ] Explicar las consecuencias de usar lru_cache sobre praw_reddit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00019-26287e8f-b23a-4e51-9645-b9fb99a93eea",
    "deepnote_cell_height": 52.390625,
    "deepnote_cell_type": "markdown",
    "id": "fbQPpvYorOAF"
   },
   "source": [
    "**Respuestas Teóricas:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00020-9507e876-349d-4beb-94e8-c7adc0bbc210",
    "deepnote_cell_height": 52.390625,
    "deepnote_cell_type": "markdown",
    "id": "RKfLXDs_rO-w"
   },
   "source": [
    "1. El cache es un espacio de memoria almacenado en la memoria RAM, disco duro o de manera remota con el fin de hacer **memoización**, es decir, acceder a resultados previamente calculados guardándolos en cache, resultando en tiempos notablemente menores de ejecución. Por otro lado, las siglas LRU vienen de \"Least Recently Used\".\n",
    "\n",
    "2. El principal costo de usar cache es aumentar el uso de memoria, aumentando directamente el costo computacional del código. Además, en caso de usar cache almacenado en disco, el acceso a los resultados almacenados puede ser muy lento, afectando negativamente al rendimiento del código.\n",
    "\n",
    "3. Finalmente, usar cache en la función anterior tiene diversas implicancias: En primer lugar, los resultados guardados en memoria serían estáticos, es decir, se guardarían en cache los posts de reddit que fueron resultado de la primera invocación de la función, por lo que invocar nuevamente la función traería esos mismos resultados y no actualizaría la información con los nuevos registros. En segundo lugar y como ya vimos, usar cache en la función disminuiría notablemente el tiempo de ejecución de la función. Finalmente, usar cache implicaría un aumento de uso de la memoria. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "00021-ed8c6162-10ed-414a-a7c0-e5eed7d2715e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_height": 66,
    "deepnote_cell_type": "code",
    "id": "X0u4WU11rLJd",
    "outputId": "a7d5e505-908e-48b4-ae23-7d2b58cd982c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 5: 20.9 s per loop\n"
     ]
    }
   ],
   "source": [
    "# aprovechamos que ya habiamos definido la función sin caché\n",
    "%%timeit \n",
    "praw_reddit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "aDRLE6xdjCfz"
   },
   "outputs": [],
   "source": [
    "@lru_cache()\n",
    "def praw_reddit(nombre_subreddit=\"chile\", n_hot=1000):\n",
    "    reddit = praw.Reddit(\n",
    "        client_id=\"-w2hyFINxZ8T3g\",\n",
    "        client_secret=\"zGPCI4s3g6Ic6AsRi7vIpP0NoxbFdw\",\n",
    "        password=\"ClasesMDS7202\",\n",
    "        user_agent=\"Clases\",\n",
    "        username=\"DocenciaDataScience\",\n",
    "        check_for_async=False,\n",
    "    )\n",
    "    subreddit = reddit.subreddit(nombre_subreddit)\n",
    "\n",
    "    votes, post, url = {}, {}, {}\n",
    "    top_submissions = list(subreddit.hot(limit=n_hot)) # obtenemos el top n de posts del foro\n",
    "    for it, top_n in enumerate(range(50, len(top_submissions), 50)):\n",
    "        top_n_submissions = top_submissions[:top_n] # obtiene los primeros 50 posts\n",
    "        upvotes, downvotes, url[it], post[it] = [], [], [], []\n",
    "\n",
    "        for submission in top_n_submissions: # para cada uno de los posts\n",
    "            try:\n",
    "                ratio = submission.upvote_ratio # obtenemos el ratio de upvote\n",
    "                ups = int( # calculamos upvotes\n",
    "                    round((ratio * submission.score) / (2 * ratio - 1))\n",
    "                    if ratio != 0.5\n",
    "                    else round(submission.score / 2)\n",
    "                )\n",
    "                upvotes.append(ups) # guardamos upvotes\n",
    "                downvotes.append(ups - submission.score) # guardamos downvotes\n",
    "                post[it].append(submission.title) # guardamos titulo del post\n",
    "                url[it].append(submission.url) # guardamos url\n",
    "            except Exception as e: # en caso de error, sigue \n",
    "                continue\n",
    "        votes[it] = np.array([upvotes, downvotes]).T\n",
    "    return votes, post, url # retorna votos, post y url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "94w4ERKojQUi",
    "outputId": "bf8fb603-959d-46a6-a8b9-39be92fcba13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 111006872.26 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1 loop, best of 5: 184 ns per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "votes, post, url = praw_reddit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00022-f295ab8f-b06d-4171-90b7-73dabfe0598d",
    "deepnote_cell_height": 52.390625,
    "deepnote_cell_type": "markdown",
    "id": "8wqZWZkyOF9j"
   },
   "source": [
    "**Respuesta de lru_cache sobre praw_reddit**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00023-56264983-6b36-48c6-a43c-19d19702f8f4",
    "deepnote_cell_height": 52.390625,
    "deepnote_cell_type": "markdown",
    "id": "jy3QxE2oOF9k"
   },
   "source": [
    "El tiempo promedio por loop de la función sin cache es de 20.9 segundos, mientras que el  tiempo de ejecución total de este ejercicio asciende a 128 segundos. Por otro lado, usar la función con cache lleva a que el tiempo promedio por loop de ejecución sea de 184 nanosegundos, mientras que el tiempo total de ejecución es de 20.5 segundos. Un aspecto importante acá es que la primera invocación a la función se lleva casi todo el tiempo de ejecución, demorando una magnitud bastaaaante superior que la ejecución más rápida. Esto último se debe a que en la primera ejecución la función aun no tiene cache, situación que cambia desde la segunda ejecución en adelante. Finalmente y en vista de los resultados, es posible concluir que se visualizan notables mejoras en cuanto a los tiempos de ejecución."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00024-87380659-431c-4ae7-9d12-6647f21ca9ff",
    "deepnote_cell_height": 542.5625,
    "deepnote_cell_type": "markdown",
    "id": "2pS26u-trdg6"
   },
   "source": [
    "## 1.3 Obtención de Mean Posterior y Standard Error [1 Punto]\n",
    "\n",
    "Una forma de obtener la mean posterior y el Standard Error de los datos de reddit es aplicando un atajo de inferencia estadística. Este atajo se define de la siguiente forma:\n",
    "\n",
    "Sea **u** los votos positivos y **d** los votos negativos del subreddit, tendremos que:\n",
    "\n",
    "$$a = 1+u$$\n",
    "\n",
    "$$b = 1+d$$\n",
    "\n",
    "$$\\sigma= 1.65\\sqrt(\\dfrac{ab}{(a + b)^2(a + b + 1)})$$\n",
    "\n",
    "$$\\mu = \\dfrac{a}{a+b}$$\n",
    "\n",
    "Donde $\\mu$ es la mean posterior y $\\sigma$ el standard error.\n",
    "\n",
    "Con lo anterior, genere dos funciones que tengan como salida $\\mu$ y $\\sigma$ de acuerdo a las ecuaciones señaladas. La primera función, deberá ser construida sin el uso de numpy, aplicando for y aplicando comandos nativos de Python. Por otro lado, deberá generar una segunda función con el uso exclusivo de numpy. **OJO** que las funciones deben tener como entrada solo un elemento del diccionario votes (por ejemplo `votes[1]`), por lo que estas no deben tener como entrada el conjunto completo de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "iVeNe753oo0U"
   },
   "outputs": [],
   "source": [
    "def fun1(votes):\n",
    "  '''\n",
    "  Una función muy mal optimizada.\n",
    "  '''\n",
    "\n",
    "  mu = []\n",
    "  sigma = []\n",
    "  for row in votes:\n",
    "    u = row[0]\n",
    "    d = row[1]\n",
    "\n",
    "    a = 1 + u\n",
    "    b = 1 + d \n",
    "\n",
    "    mu.append(a/(a+b) )\n",
    "    sigma.append(1.65 * ((a*b)/(((a+b)**2) * (a+b+1)))**(1/2))\n",
    "\n",
    "  return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "YxzCLJchf_Gw"
   },
   "outputs": [],
   "source": [
    "def fun2(votes):\n",
    "  '''\n",
    "  Una función un poco mejor optimizada.\n",
    "  '''\n",
    "\n",
    "  a = np.ones(1) + votes[:, 0]\n",
    "  b = np.ones(1) + votes[:, 1]\n",
    "\n",
    "  mu = np.divide(a, a+b)\n",
    "  sigma = 1.65 * np.sqrt(np.divide(a*b, np.multiply((a+b)**2, a+b+1)))\n",
    "\n",
    "  return mu, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00026-42ed3992-3ac8-4452-b6f1-031bb91fa5e6",
    "deepnote_cell_height": 352,
    "deepnote_cell_type": "markdown",
    "id": "VhHhiTRYwpGu",
    "owner_user_id": "badcc427-fd3d-4615-9296-faa43ec69cfb"
   },
   "source": [
    "## 1.4 Comparación de Rendimiento [2 Puntos]\n",
    "\n",
    "Ahora, aplique el compilador **Numba** sobre las funciones 1.3 y compare el tiempo de ejecución con los obtenidos sin el compilador. \n",
    "\n",
    "Para esto genere un gráfico de linea utilizando plotly, en donde se pueda observar el tiempo que toma ejecutar cada función (el eje y) diferentes cantidades de datos (ejemplo, en el eje x considerar 100, 200, 300, ..., 1000 datos) sobre cada función implementada (series `Python`, `Numpy`, `Python-JIT`, `Numpy-JIT`). ¿Es posible observar diferencias? ¿A qué se debe esto?.\n",
    "\n",
    "**Nota:** Ejecuten las funciones compiladas con algún ejemplo antes de graficar. De lo contrario, les indicará el tiempo de compilación, cosa que no queremos medir\n",
    "\n",
    "**Nota 2**: En el caso que su computador sea muy rápido, se recomienda graficar el eje y (tiempo) como logaritmo usando `log_y=True`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": "00027-a686fa21-e957-40c6-8fd1-a6fef560928c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_height": 66,
    "deepnote_cell_type": "code",
    "id": "b02IokToxPpO",
    "outputId": "e18f6577-b3fa-44a3-de25-579323a2b00e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.53977273, 0.82706767, 0.94444444, 0.87096774, 0.96363636,\n",
       "        0.93421053, 0.9122807 , 0.92941176, 0.8627451 , 0.95238095,\n",
       "        0.84848485, 0.83636364, 0.875     , 0.87434555, 0.95      ,\n",
       "        0.94761905, 0.79166667, 0.97935103, 0.80952381, 0.97594502,\n",
       "        0.88888889, 0.84615385, 0.79166667, 0.59821429, 0.88571429,\n",
       "        0.76      , 0.94520548, 0.82857143, 0.76470588, 0.8       ,\n",
       "        0.95535714, 0.98879552, 0.88861985, 0.90807799, 0.66666667,\n",
       "        0.66666667, 0.91919192, 0.9047619 , 0.81081081, 0.93820225,\n",
       "        0.98039216, 0.71612903, 0.5625    , 0.8       , 0.73333333,\n",
       "        0.88679245, 0.578125  , 0.77380952, 0.58333333, 0.95454545,\n",
       "        0.91752577, 0.625     , 0.5       , 0.5       , 0.93939394,\n",
       "        0.64615385, 0.86      , 0.90784983, 0.81578947, 0.7826087 ,\n",
       "        0.93693694, 0.5       , 0.86813187, 0.8943662 , 0.79411765,\n",
       "        0.94      , 0.86842105, 0.57894737, 0.79411765, 0.87179487,\n",
       "        0.80392157, 0.75862069, 0.95061728, 0.53846154, 0.5       ,\n",
       "        0.71186441, 0.5       , 0.70967742, 0.90789474, 0.85714286,\n",
       "        0.96710526, 0.73913043, 0.81818182, 0.82608696, 0.90243902,\n",
       "        0.76      , 0.95454545, 0.90196078, 0.5       , 0.875     ,\n",
       "        0.87878788, 0.5483871 , 0.6       , 0.55555556, 0.94736842,\n",
       "        0.93877551, 0.54545455, 0.91860465, 0.96396396, 0.97660819]),\n",
       " array([0.0618143 , 0.03818888, 0.02679226, 0.06968894, 0.02931654,\n",
       "        0.04661645, 0.06128889, 0.04557272, 0.05594619, 0.04392276,\n",
       "        0.10145993, 0.04737698, 0.10913724, 0.0394697 , 0.04604324,\n",
       "        0.01791622, 0.13401842, 0.00735408, 0.13813628, 0.01479475,\n",
       "        0.08524827, 0.1591065 , 0.09572744, 0.07609749, 0.08749344,\n",
       "        0.13820052, 0.02531654, 0.10364283, 0.16496828, 0.26944387,\n",
       "        0.02271703, 0.00649501, 0.02551207, 0.02512488, 0.29398737,\n",
       "        0.29398737, 0.04496913, 0.04704392, 0.1048335 , 0.01717678,\n",
       "        0.02254136, 0.05956317, 0.19852252, 0.07570719, 0.18241436,\n",
       "        0.07114359, 0.10107181, 0.07487359, 0.22561348, 0.0276061 ,\n",
       "        0.04584998, 0.26626761, 0.47631397, 0.47631397, 0.04809816,\n",
       "        0.09711519, 0.08017004, 0.02783334, 0.1024231 , 0.09927238,\n",
       "        0.0219459 , 0.47631397, 0.058204  , 0.04241066, 0.11277216,\n",
       "        0.03899086, 0.08931204, 0.18216154, 0.0570001 , 0.08721954,\n",
       "        0.09084563, 0.12890972, 0.03947911, 0.11298669, 0.47631397,\n",
       "        0.09647292, 0.47631397, 0.13239752, 0.05437491, 0.08804958,\n",
       "        0.01376658, 0.14789401, 0.18371173, 0.12766072, 0.04396632,\n",
       "        0.13820052, 0.03262191, 0.06804183, 0.47631397, 0.09499178,\n",
       "        0.09235481, 0.14515625, 0.17639242, 0.25927249, 0.05899759,\n",
       "        0.03975665, 0.23717082, 0.04837137, 0.02059351, 0.01901568]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numba import jit\n",
    "\n",
    "@jit(nopython=True)\n",
    "def fun1_numba(votes):\n",
    "  '''\n",
    "  Una función muy mal optimizada.\n",
    "  '''\n",
    "\n",
    "  mu = []\n",
    "  sigma = []\n",
    "  for row in votes:\n",
    "    u = row[0]\n",
    "    d = row[1]\n",
    "\n",
    "    a = 1 + u\n",
    "    b = 1 + d \n",
    "\n",
    "    mu.append(a/(a+b) )\n",
    "    sigma.append(1.65 * ((a*b)/(((a+b)**2) * (a+b+1)))**(1/2))\n",
    "\n",
    "  return mu, sigma\n",
    "\n",
    "@jit(nopython=True)\n",
    "def fun2_numba(votes):\n",
    "  '''\n",
    "  Una función un poco mejor optimizada.\n",
    "  '''\n",
    "\n",
    "  a = np.ones(1) + votes[:, 0]\n",
    "  b = np.ones(1) + votes[:, 1]\n",
    "\n",
    "  mu = np.divide(a, a+b)\n",
    "  sigma = 1.65 * np.sqrt(np.divide(a*b, np.multiply((a+b)**2, a+b+1)))\n",
    "\n",
    "  return mu, sigma\n",
    "\n",
    "# ejecutamos ambas funciones por primera vez\n",
    "fun1_numba(votes[1])\n",
    "fun2_numba(votes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNTysy_xyS7F"
   },
   "source": [
    "Luego, generamos la función `return_time` para devolver el tiempo de ejecución para cada función. Nos aprovecharemos de que `votes` tiene batches de diferente tamaño (batches de tamaño 50, 100, 150, etc..) para ir graficando a medida que aumenta el tamaño del batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "meIj44Rlv8KX"
   },
   "outputs": [],
   "source": [
    "def return_time(func, batch):\n",
    "\n",
    "  '''\n",
    "  Función que recibe una función de cálculo y un batch de tamaño n, devuelve el tiempo de computación.\n",
    "  func: función que calcula mean posterior y std\n",
    "  batch: batch de datos a calcular\n",
    "  '''\n",
    "\n",
    "  t0 = time.process_time() # tiempo inicial\n",
    "  func(batch)\n",
    "  t1 = time.process_time()\n",
    "  return t1 - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "UUMootszQOvk",
    "outputId": "5409e8c5-e972-4e6d-a2b1-b8b5438c1c84"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"9c46bd03-5114-42a9-ab54-1d79c2b51e8a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9c46bd03-5114-42a9-ab54-1d79c2b51e8a\")) {                    Plotly.newPlot(                        \"9c46bd03-5114-42a9-ab54-1d79c2b51e8a\",                        [{\"hovertemplate\":\"tipo=Python<br>it=%{x}<br>Tiempo=%{y}<extra></extra>\",\"legendgroup\":\"Python\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"Python\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[50,100,150,200,250,300,350,400,450,500,550,600,650,700,750,800,850,900,950],\"xaxis\":\"x\",\"y\":[0.00014016199999922208,0.00018405099999974084,0.0003063129999993919,0.00037533400000100414,0.00048105900000017243,0.0005554620000012278,0.0006554389999990917,0.0007605630000000474,0.0008290730000002355,0.0009199219999995734,0.0009973510000005348,0.0011187049999996646,0.001188053999999994,0.0012519690000001304,0.001323068999999677,0.0014439230000000691,0.0013924510000009604,0.0015058620000001355,0.0017392069999999649],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"tipo=Numpy<br>it=%{x}<br>Tiempo=%{y}<extra></extra>\",\"legendgroup\":\"Numpy\",\"line\":{\"color\":\"#EF553B\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"Numpy\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[50,100,150,200,250,300,350,400,450,500,550,600,650,700,750,800,850,900,950],\"xaxis\":\"x\",\"y\":[0.0001177170000001837,2.9836999999588443e-05,3.370900000021493e-05,3.086400000107403e-05,4.2921999998668525e-05,3.103500000101178e-05,4.455799999902865e-05,3.393799999962255e-05,3.1871000000904814e-05,4.657499999893844e-05,4.612600000086786e-05,3.728000000080556e-05,3.290099999908591e-05,3.456299999982093e-05,3.34210000012547e-05,6.084700000030807e-05,4.6511999999054865e-05,0.00011222500000052094,5.590700000013271e-05],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"tipo=Python-JIT<br>it=%{x}<br>Tiempo=%{y}<extra></extra>\",\"legendgroup\":\"Python-JIT\",\"line\":{\"color\":\"#00cc96\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"Python-JIT\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[50,100,150,200,250,300,350,400,450,500,550,600,650,700,750,800,850,900,950],\"xaxis\":\"x\",\"y\":[1.9041999999913628e-05,1.116899999864529e-05,1.6543999999285575e-05,1.9180999998980042e-05,2.3901000000492445e-05,2.7277000000935914e-05,2.7756999999795084e-05,4.638599999928772e-05,4.408299999880683e-05,5.0568000000694724e-05,4.687000000025421e-05,6.085999999960734e-05,6.183200000009492e-05,8.029899999861811e-05,7.268200000076774e-05,7.196900000039363e-05,8.855899999993255e-05,7.800000000024454e-05,8.534700000062401e-05],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"tipo=Numpy-JIT<br>it=%{x}<br>Tiempo=%{y}<extra></extra>\",\"legendgroup\":\"Numpy-JIT\",\"line\":{\"color\":\"#ab63fa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"Numpy-JIT\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[50,100,150,200,250,300,350,400,450,500,550,600,650,700,750,800,850,900,950],\"xaxis\":\"x\",\"y\":[9.924000000438582e-06,1.4539999998675057e-05,7.279000000082192e-06,4.481999999583763e-06,5.884000000122569e-06,5.010999998944499e-06,6.023999999271723e-06,5.723000001012224e-06,6.040000000595569e-06,1.3843999999707535e-05,7.012999999389535e-06,7.180999999079063e-06,6.761999999937984e-06,6.889999999870611e-06,7.5790000000353075e-06,8.723999998849763e-06,8.289000000161195e-06,9.331000001111533e-06,9.499000000801061e-06],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"it\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Tiempo\"},\"type\":\"log\"},\"legend\":{\"title\":{\"text\":\"tipo\"},\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('9c46bd03-5114-42a9-ab54-1d79c2b51e8a');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# obtenemos tiempos de ejecución para cada función\n",
    "fun1_times, fun2_times, fun1_numba_times, fun2_numba_times = [], [], [], []\n",
    "for it, batch in votes.items():\n",
    "  fun1_times.append(return_time(fun1, batch))\n",
    "  fun2_times.append(return_time(fun2, batch))\n",
    "  fun1_numba_times.append(return_time(fun1_numba, batch))\n",
    "  fun2_numba_times.append(return_time(fun2_numba, batch))\n",
    "\n",
    "# generamos dataframe y melt para graficar\n",
    "df_times = pd.DataFrame({'Python': fun1_times, 'Numpy': fun2_times, 'Python-JIT': fun1_numba_times, 'Numpy-JIT': fun2_numba_times})\n",
    "df_times = df_times.melt(var_name = 'tipo', value_name = 'Tiempo')\n",
    "df_times['it'] = (df_times.groupby('tipo').cumcount() + 1) * 50\n",
    "\n",
    "# graficamos usando plotly\n",
    "fig = px.line(df_times, x = 'it', y = 'Tiempo', color = 'tipo', log_y = True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UYlxvO3gy9aX"
   },
   "source": [
    "En vista del gráfico, es posible visualizar una notoria diferencia en los tiempso de ejecución de las funciones: \n",
    "\n",
    "1. En primer lugar, notamos que la función hecha en Python obtiene por lejos el peor rendimiento, alcanzo tiempos de ejecución bastante superiores que las demás implementaciones. Esto es esperable pues se está usando código python nativo y no se usa ningún tipo de optimización de código.\n",
    "\n",
    "2. En segundo lugar, notamos que las implementaciones Numpy y Python-JIT obtienen rendimientos bastante similares. Esto es interesante, pues tanto Numpy como JIT optimizan el código de alguna forma: mientras que Numpy lo hace a través de la vectorización de las operaciones, JIT optimiza el código usando compilación de código, moviendo el código de alto nivel a lenguaje de máquina y por lo tanto disminuyendo considerablemente los tiempos de ejecución.\n",
    "\n",
    "3. Finalmente, se observa que la combinación de Numpy y JIT es la más rentable en términos de tiempos de ejecución, superando con creces el rendimiento de las otras implementaciones. La razón de su rendimiento se debe a que se aprovecha la optimización tanto de Numpy (operaciones vectoriales) como de JIT (compilación de código), logrando excelentes resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00030-01881ca2-384a-44f1-bcaf-ad095552aac2",
    "deepnote_cell_height": 70,
    "deepnote_cell_type": "markdown",
    "id": "DljdJw8m0gYC"
   },
   "source": [
    "## 1.5 Plot de Resultados de Análisis de Votos [1 Punto]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00031-1bfb8e5a-3a40-45f2-8f0f-f94c9264f8e2",
    "deepnote_cell_height": 111.1875,
    "deepnote_cell_type": "markdown",
    "id": "cQAxOM5D08Hl"
   },
   "source": [
    "Llego la hora de visualizar los resultados obtenidos, para esto solo ejecute las siguientes celdas y observe lo que sucede :3. ¿Qué logra observar de los resultados?, ¿La solución resulta trivial?\n",
    "\n",
    "En esta sección esperamos que solo comenten con lo que logran visualizar de los dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": "00032-107c679d-f291-40ec-8854-fd17864ba743",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_height": 318,
    "deepnote_cell_type": "code",
    "id": "N5E2mNYXaafI",
    "outputId": "0c38676c-9dac-4714-cfa0-e20201899075",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower bounds aproximados:\n",
      "\n",
      "Top 20 post ordenador por el limite inferior:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "votos = votes[len(votes) - 1]\n",
    "posteo = post[len(post) - 1]\n",
    "print(\"lower bounds aproximados:\")\n",
    "#posterior_mean, std_err = intervals_numpy(votos[:, 0], votos[:, 1]) # comentamos esta función pues habia que remplazarla por la nuestra :p\n",
    "posterior_mean, std_err = fun2_numba(votos)\n",
    "lb = posterior_mean - std_err\n",
    "print(\"\\nTop 20 post ordenador por el limite inferior:\\n\")\n",
    "order = np.argsort(-lb)\n",
    "vote_post = {\n",
    "    'Votos (+)': votos[order[:20], 0],\n",
    "    'Votos (-)': votos[order[:20], 1],\n",
    "    'Post': np.array(posteo)[order[:20]],\n",
    "    'url': np.array(url[len(url) - 1])[order[:20]]\n",
    "}\n",
    "df = pd.DataFrame(data=vote_post)\n",
    "ordered_post = df.Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": "2a0efceb16224059bb6aca51848d260f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "deepnote_cell_height": 210,
    "deepnote_cell_type": "code",
    "id": "pWAuncTMOF9t",
    "outputId": "525a52be-4008-4a82-a8e7-144e59b8bb5a",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"8de20642-2144-468a-9a0d-ff6cadaaaf0c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8de20642-2144-468a-9a0d-ff6cadaaaf0c\")) {                    Plotly.newPlot(                        \"8de20642-2144-468a-9a0d-ff6cadaaaf0c\",                        [{\"error_x\":{\"array\":[0.014076848109573367,0.007994488500260716,0.007913170105126278,0.013672805704055482,0.013607709336504634,0.0073540811670295405,0.01316882925009965,0.011557673881135221,0.01042581133830738,0.009508376343156169,0.008239355382255,0.008442347695747242,0.0075329839041795256,0.006495013462018683,0.006233930431959205,0.00631058901153957,0.00763880626119605,0.00736599736606806,0.0070814792798024285,0.005956639602100079]},\"hovertemplate\":\"mean=%{x}<br>post=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"h\",\"showlegend\":false,\"x\":[0.9850746268656716,0.9792147806004619,0.9794285714285714,0.9855072463768116,0.9855769230769231,0.9793510324483776,0.986046511627907,0.9858657243816255,0.9872611464968153,0.987012987012987,0.9876796714579056,0.988479262672811,0.9887429643527205,0.988795518207283,0.9885931558935361,0.9891156462585035,0.9953488372093023,0.9955156950672646,0.9956896551724138,0.9963768115942029],\"xaxis\":\"x\",\"y\":[\"Detienen a enfermera y su pareja por ataque contra su compa\\u00f1era de trabajo en Las Condes\",\"Los l\\u00edmites del humor\",\"Encontr\\u00e9 una joya ctm. Japoneses del colegio cantando el himno nacional.\",\"Una curiosa nota period\\u00edstica publicada en Septiembre de 1940 que me encontr\\u00e9.\",\"M\\u00e9dicos usaban RUT de pacientes Fonasa para simular atenciones que nunca sucedieron: as\\u00ed se gest\\u00f3 el millonario fraude\",\"siempre va a haber un hueon mas loco que tu en la calle\",\"Alcalde de Arica advierte alarmante situaci\\u00f3n por cr\\u00edmenes de \\\"Tren de Aragua\\\" en la zona: \\\"Es como estar en un cap\\u00edtulo de Breaking Bad\\\"\",\"Toxicidad en el \\u00e1rea de la salud en Chile\",\"Hoy falleci\\u00f3 la profesora Victoria Castro, una de las impulsoras de la arqueolog\\u00eda chilena y formadora de varias generaciones de arque\\u00f3los. Gran mujer.\",\"Alumna fue apu\\u00f1alada tras oponerse a continuidad de toma en liceo de Concepci\\u00f3n\",\"Con raz\\u00f3n hay tanto taco\",\"Otros tiempos\",\"la situaci\\u00f3n de los pud\\u00faes en Chilo\\u00e9 es cr\\u00edtica. @chiloesilvestre\",\"Pud\\u00fa en mi u \\ud83e\\udd20\",\"Bolos\",\"ahora no po'\",\"Macabro hallazgo en San Jos\\u00e9 de Maipo: perro lleg\\u00f3 a su casa con una cabeza humana | Nacional | BioBioChile\",\"Empresa le paga por error sueldo de $ 165 millones a trabajador, \\u00e9ste desaparece... y luego renuncia\",\"Gobierno queda fuera de querella por asesinato de carabinero: abogado se qued\\u00f3 dormido\",\"Juraba que esta wea era un sue\\u00f1o febril de chico\"],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"mean\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"post\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('8de20642-2144-468a-9a0d-ff6cadaaaf0c');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r_order = order[::-1][-20:]\n",
    "data_dic = {\n",
    "    'mean': posterior_mean[r_order],\n",
    "    'std_err': std_err[r_order],\n",
    "    'post': ordered_post[::-1]\n",
    "}\n",
    "df = pd.DataFrame(data=data_dic)\n",
    "fig = px.scatter(df, x=\"mean\", y=\"post\", error_x=\"std_err\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00033-eddd71de-b9a7-4779-924a-964c68603845",
    "deepnote_cell_height": 52.390625,
    "deepnote_cell_type": "markdown",
    "id": "szOjXLKA1Rif"
   },
   "source": [
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00034-92ca5c7c-071c-4e99-9f17-dec033ed4c24",
    "deepnote_cell_height": 52.390625,
    "deepnote_cell_type": "markdown",
    "id": "0F83QdD61Pd1"
   },
   "source": [
    "Analizando los resultados del gráfico, notamos que, a pesar de que los posts estan ordenados por el límite inferior, sus medias no estan necesariamente ordenadas. Lo anterior implica que si bien un post puede tener un límite inferior menor que el límite inferior de otro post, esto no implica que el ratio $\\frac{upvotes}{total\\_votes}$ sigan el mismo orden. En ese sentido, la gran conclusión es que para concluir que un post es bueno o malo se debe considerar el análisis tanto de la media como de la desviación estándar y no cada una por sí sola, resultando en un análisis no trivial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00035-93d50cd9-ff61-4aa8-ae41-e84009a3f64e",
    "deepnote_cell_height": 269,
    "deepnote_cell_type": "markdown",
    "id": "Rg4ZMq8ezAH6"
   },
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://media1.tenor.com/images/fb5bf7cc5a4acb91b4177672886a88ba/tenor.gif?itemid=5591338\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "id": "1Uu4a0qyOF9w",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=87110296-876e-426f-b91d-aaf681223468' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab9_Enunciado.ipynb",
   "provenance": []
  },
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "86c0ae4d-10d9-41be-9dc9-0e76fdf26f7b",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Tabla de Contenidos",
   "title_sidebar": "Contenidos",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "241.867px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
